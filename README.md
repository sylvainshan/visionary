# ğŸ§  NX-414 - Predicting Neural Activity

This project provides a modular pipeline for training and evaluating different models on neural activity data from the IT cortex. It supports both classical regression models and modern task- or data-driven architectures.

---

## ğŸš€ Getting Started

Make sure all required dependencies are installed (`numpy`, `pandas`, `matplotlib`, `seaborn`, `torch`, `torchvision`, `scikit-learn`, `h5py`, `gdown`, `tqdm`, `scipy`), then run:

```bash
python main.py [--model MODEL_NAME] [--augment]
```

If no model is specified, the script defaults to `best`.

âš ï¸ We recommend having more than 64GB of memory to handle larger models and datasets efficiently.

---

## âš™ï¸ Command-Line Arguments

### `--model`

Specifies which model to run.

**Choices:**

- `linear` â€“ Basic Linear Regression
- `linear_pca` â€“ Linear Regression with PCA
- `ridge_cv5` â€“ Ridge Regression with 5-fold Cross-Validation
- `ridge_pca_cv5` â€“ Ridge Regression with PCA and CV
- `task-driven_trained` â€“ Task-driven model using trained weights
- `task-driven_random` â€“ Task-driven model using random weights
- `data-driven` â€“ Data-driven shallow CNN model
- `resnet_adapter` â€“ Data-driven shallow CNN model (Best)
- `vgg_bn` â€“ Data-driven shallow CNN model
- `best` â€“ Best-performing model (default)
- `all` â€“ Run all models sequentially

**Default:** `best`

---

### `--augment`

If set, uses the augmented dataset instead of the original dataset.

```bash
--augment
```

This flag has no argument â€” it's either used or not used.

---

## ğŸ“† Output

- Model performance metrics are logged to a CSV file at:

  ```
  out/metrics_log.csv
  ```

- Each row in the CSV includes:

  - `datetime` â€“ Timestamp of the run
  - `model` â€“ Name of the model used
  - `augment` â€“ Whether augmentation was used (1 or 0)
  - `r2` â€“ RÂ² Score
  - `mse` â€“ Mean Squared Error
  - `mae` â€“ Mean Absolute Error
  - `mape` â€“ Mean Absolute Percentage Error
  - `ev_avg` â€“ Average Explained Variance
  - `corr_avg` â€“ Average Pearson Correlation

---

## ğŸ“Š Output Figures

This project generates several plots that help analyze model performance and behavior. All figures are saved under the `out/` directory. Below is a description of the figures generated:

- Correlation and Explained Variance Distributions

  **Directory:** `out/corr_exp_var_histogram/{model_name}_hist.png`
  A two-panel plot displaying histograms and boxplots for:

  - Pearson correlation coefficients
  - Explained variance (EV) scores

  Each metric is shown as a percentage across all neurons. Helps assess model performance distributionally.

---

- Layer-wise Explained Variance
  **Directory:** `out/layer_comparison/{model_type}_layer_comparison.png` 
  Bar plot comparing explained variance across layers of a model. Useful for understanding how information is represented at different stages in task-driven architectures.

---

- Representational Dissimilarity Matrices (RDMs)
  **Directory:** `out/rdm/{model_name}_predicted_rdm.png`
  Visual comparison between predicted and ground truth RDMs. RDMs are rank-normalized and sorted by semantic categories. Helps evaluate how closely model representations align with neural population activity.

---

- Single Neuron Response Profiles

  **Directory:** `out/neuron_site/{model_name}_site{site_index}.png`  
  Line plot showing predicted vs. true neural responses for a specific neuron (site), across all stimuli. Object categories are indicated via background grouping. Great for detailed per-site inspection.


## ğŸ§ª Example Usage

Run the best model (default behavior):

```bash
python main.py
```

Run Ridge Regression with PCA and 5-fold CV using augmented data:

```bash
python main.py --model ridge_pca_cv5 --augment
```

Run all models and log results to CSV:

```bash
python main.py --model all
```

---

## ğŸ“ Project Structure (simplified)

```
project/
â”‚
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ data/                   # Raw and augmented data
â””â”€â”€ out/
    â”œâ”€â”€ metrics_log.csv     # Metrics log file
    â”œâ”€â”€ corr_exp_var_histogram/     # Histogram plots
    â”œâ”€â”€ layer_comparison/     # Layer comparison plots
    â”œâ”€â”€ neuron_site/         # Single site prediction plots
    â””â”€â”€ rdm/         # Representational dissimilarity matrices plots
```

## ğŸ”’ Reproducibility

To ensure reproducible results, we set random seeds for Python, NumPy, and PyTorch. This also includes configuring the CUDA backend and DataLoader workers. By fixing these seeds and environment variables, we minimize variability across runs, though minor variations in results might still be observed.

---
